# -*- coding: utf-8 -*-
"""2.generate_gray_image_from_points.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SoF3NJ8Fp4fpL4CkU3HXyR2u7IF6LXPW
"""

!rm -rf waymo-od > /dev/null
!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od
!cd waymo-od && git branch -a
!cd waymo-od && git checkout remotes/origin/master
!pip3 install --upgrade pip
!pip3 install opencv-python
!pip3 install --upgrade numpy
!pip3 install --upgrade opencv-python

!pip3 install waymo-open-dataset-tf-2-11-0==1.6.1

import os
import tensorflow.compat.v1 as tf
import math
import itertools
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import cv2


tf.enable_eager_execution()

from waymo_open_dataset.utils import range_image_utils
from waymo_open_dataset.utils import transform_utils
from waymo_open_dataset.utils import  frame_utils
from waymo_open_dataset import dataset_pb2 as open_dataset

from google.colab import drive

drive.mount('/content/gdrive')
FILENAME = '/content/gdrive/My Drive/ColabNotebooks/tfrecord/individual_files_training_segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord'
dataset = tf.data.TFRecordDataset(FILENAME)
# 从文件路径中提取文件名
file_name = os.path.basename(FILENAME)
# 创建一个以文件名命名的文件夹
folder_path_save = os.path.join('/content/gdrive/My Drive/ColabNotebooks/filterimage', file_name.split('.')[0])
os.makedirs(folder_path_save, exist_ok=True)

# frame_count = 104
# for i, data in enumerate(dataset, 1):
# 	if i < 104:
# 			continue
frame_count = 1
for data in dataset:
	frame = open_dataset.Frame()
	frame.ParseFromString(bytearray(data.numpy()))
	# 从 frame 中获取 laser_calibrations 中的 beam_inclinations
	beam_inclinations_proto = None
	laser_name = open_dataset.LaserName.TOP
	for calibration in frame.context.laser_calibrations:
			if calibration.name == laser_name:
				beam_inclinations_proto = calibration
				break

	if beam_inclinations_proto is not None:
    # 提取 beam_inclinations，并将其排序从高到低
		beam_inclinations = np.array(beam_inclinations_proto.beam_inclinations[:64], dtype=np.float32)
		sorted_beam_inclinations = np.sort(beam_inclinations)[::-1]  # 从高到低排序
    # 如果不足64个值，补零
		if len(sorted_beam_inclinations) < 64:
			sorted_beam_inclinations = np.pad(sorted_beam_inclinations, (0, 64 - len(sorted_beam_inclinations)), 'constant')
	else:
    # 如果没有找到符合条件的 laser_calibrations，则创建一个空的数组
		sorted_beam_inclinations = np.zeros(64, dtype=np.float32)

# 调整形状为 (1, 64)
	sorted_beam_inclinations = np.expand_dims(sorted_beam_inclinations, axis=0)

# 转换为张量
	inclinations_tensor = tf.constant(sorted_beam_inclinations, dtype=tf.float32)
	inclination = inclinations_tensor
	num_rows = inclination.shape[1]


	laser_name = open_dataset.LaserName.TOP  # 假设你需要的是 TOP激光雷达的 extrinsic
	extrinsic_proto = None
	for calibration in frame.context.laser_calibrations:
		if calibration.name == laser_name:
			extrinsic_proto = calibration.extrinsic
			break

# 将 extrinsic 转换为齐次变换矩阵形式
	extrinsic_values = np.array([
    [extrinsic_proto.transform[0], extrinsic_proto.transform[1], extrinsic_proto.transform[2], extrinsic_proto.transform[3]],
    [extrinsic_proto.transform[4], extrinsic_proto.transform[5], extrinsic_proto.transform[6], extrinsic_proto.transform[7]],
    [extrinsic_proto.transform[8], extrinsic_proto.transform[9], extrinsic_proto.transform[10], extrinsic_proto.transform[11]],
    [extrinsic_proto.transform[12], extrinsic_proto.transform[13], extrinsic_proto.transform[14], extrinsic_proto.transform[15]]
	])
	extrinsic = tf.constant([extrinsic_values], dtype=tf.float32)
	break

####filtered_points
batch = 1
num_cols = 2650

import os
import pickle

folder_path = '/content/gdrive/My Drive/ColabNotebooks/points_from_howie/filtered/segment-10526338824408452410_5714_660_5734_660_with_camera_labels'

i = 1
while True:
    file_name = f'points_{i}.pkl'
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        with open(file_path, 'rb') as f:
            array = pickle.load(f)
            last_three_values = np.array([point[-3:] for point in array])
            points = tf.tile(
              tf.expand_dims(last_three_values, axis=0), [batch, 1, 1])
            num_points_per_batch = last_three_values.shape[0]
            num_points = tf.constant([num_points_per_batch], dtype=tf.int32)
            points_tensor = tf.convert_to_tensor(points)

            range_image, _, _ = range_image_utils.build_range_image_from_point_cloud(
              points_tensor, num_points, extrinsic, inclination, [num_rows, num_cols])

            save_gray_image(range_image, folder_path_save, f"image_{i}_filter.png")
            print(f"Data saved successfully to filter {i}")
            #print(f"File: {file_name}, Last three values: {last_three_values}")
        i += 1
    else:
        #print(f"File {file_name} does not exist.")
        break

def save_gray_image(range_image, folder_path, save_path):

    # 范围图像数据重新整形为原始形状
    range_image_numpy = range_image.numpy()  # 将 TensorFlow 张量转换为 NumPy 数组
    # 创建一个用于掩盖无效范围的掩码，将负值（无效范围）设为一个很大的正值，这里设为 1e10
    # lidar_image_mask = range_image_numpy >= 0
    # range_image_numpy = np.where(lidar_image_mask, range_image_numpy, 1e10)

    range_image_numpy = np.where(range_image_numpy == 0, 254, range_image_numpy)
    range_image_numpy = np.where(np.logical_and(range_image_numpy >= 0, range_image_numpy < 254), 0, range_image_numpy)
    range_image_numpy = np.where(range_image_numpy == 254, 1, range_image_numpy)
    # 展示范围图像的范围
    # 调整图像尺寸为 64x2650
    # resized_image = np.zeros((64, 2650), dtype=np.uint8)
    # resized_image[:, :] = range_image_numpy[0]


    # 保存为灰度图像
    cv2.imwrite(os.path.join(folder_path, save_path), range_image_numpy[0])

def build_range_image_from_point_cloud(points_vehicle_frame,
                                       num_points,
                                       extrinsic,
                                       inclination,
                                       range_image_size,
                                       point_features=None,
                                       dtype=tf.float32,
                                       scope=None):
  """Build virtual range image from point cloud assuming uniform azimuth.

  Args:
    points_vehicle_frame: tf tensor with shape [B, N, 3] in the vehicle frame.
    num_points: [B] int32 tensor indicating the number of points for each frame.
    extrinsic: tf tensor with shape [B, 4, 4].
    inclination: tf tensor of shape [B, H] that is the inclination angle per
      row. sorted from highest value to lowest.
    range_image_size: a size 2 [height, width] list that configures the size of
      the range image.
    point_features: If not None, it is a tf tensor with shape [B, N, 2] that
      represents lidar 'intensity' and 'elongation'.
    dtype: the data type to use.
    scope: tf name scope.

  Returns:
    range_images : [B, H, W, 3] or [B, H, W] tensor. Range images built from the
      given points. Data type is the same as that of points_vehicle_frame. 0.0
      is populated when a pixel is missing.
    ri_indices: tf int32 tensor [B, N, 2]. It represents the range image index
      for each point.
    ri_ranges: [B, N] tensor. It represents the distance between a point and
      sensor frame origin of each point.
  """

  with tf.compat.v1.name_scope(
      scope,
      'BuildRangeImageFromPointCloud',
      values=[points_vehicle_frame, extrinsic, inclination]):
    points_vehicle_frame_dtype = points_vehicle_frame.dtype

    points_vehicle_frame = tf.cast(points_vehicle_frame, dtype)
    extrinsic = tf.cast(extrinsic, dtype)
    inclination = tf.cast(inclination, dtype)
    height, width = range_image_size

    # [B, 4, 4]
    vehicle_to_laser = tf.linalg.inv(extrinsic)
    # [B, 3, 3]
    rotation = vehicle_to_laser[:, 0:3, 0:3]
    # [B, 1, 3]
    translation = tf.expand_dims(vehicle_to_laser[::, 0:3, 3], 1)
    # Points in sensor frame
    # [B, N, 3]
    points = tf.einsum('bij,bkj->bik', points_vehicle_frame,
                       rotation) + translation
    # [B, N]
    xy_norm = tf.norm(tensor=points[..., 0:2], axis=-1)
    # [B, N]
    point_inclination = tf.atan2(points[..., 2], xy_norm)
    # [B, N, H]
    point_inclination_diff = tf.abs(
        tf.expand_dims(point_inclination, axis=-1) -
        tf.expand_dims(inclination, axis=1))
    # [B, N]
    point_ri_row_indices = tf.argmin(
        input=point_inclination_diff, axis=-1, output_type=tf.int32)
    # [B, 1], within [-pi, pi]
    az_correction = tf.expand_dims(
        tf.atan2(extrinsic[..., 1, 0], extrinsic[..., 0, 0]), -1)
    # [B, N], within [-2pi, 2pi]
    point_azimuth = tf.atan2(points[..., 1], points[..., 0]) + az_correction

    point_azimuth_gt_pi_mask = point_azimuth > np.pi
    point_azimuth_lt_minus_pi_mask = point_azimuth < -np.pi
    point_azimuth = point_azimuth - tf.cast(
        point_azimuth_gt_pi_mask, dtype=dtype) * 2 * np.pi
    point_azimuth = point_azimuth + tf.cast(
        point_azimuth_lt_minus_pi_mask, dtype=dtype) * 2 * np.pi

    # [B, N].
    point_ri_col_indices = width - 1.0 + 0.5 - (point_azimuth +
                                                np.pi) / (2.0 * np.pi) * width
    point_ri_col_indices = tf.cast(
        tf.round(point_ri_col_indices), dtype=tf.int32)

    with tf.control_dependencies([
        tf.compat.v1.assert_non_negative(point_ri_col_indices),
        tf.compat.v1.assert_less(point_ri_col_indices, tf.cast(width, tf.int32))
    ]):
      # [B, N, 2]
      ri_indices = tf.stack([point_ri_row_indices, point_ri_col_indices], -1)
      # [B, N]
      ri_ranges = tf.cast(
          tf.norm(tensor=points, axis=-1), dtype=points_vehicle_frame_dtype)
      print('****************************')
      def fn(args):
        """Builds a range image for each frame.

        Args:
          args: a tuple containing:
            - ri_index: [N, 2] int tensor.
            - ri_value: [N] float tensor.
            - num_point: scalar tensor
            - point_feature: [N, 2] float tensor.

        Returns:
          range_image: [H, W]
        """
        if len(args) == 3:
          ri_index, ri_value, num_point = args
        else:
          ri_index, ri_value, num_point, point_feature = args
          ri_value = tf.concat([ri_value[..., tf.newaxis], point_feature],
                               axis=-1)
          ri_value = encode_lidar_features(ri_value)

        # pylint: disable=unbalanced-tuple-unpacking
        ri_index = ri_index[0:num_point, :]
        ri_value = ri_value[0:num_point, ...]
        range_image = scatter_nd_with_pool(ri_index, ri_value, [height, width],
                                           tf.math.unsorted_segment_min)
        if len(args) != 3:
          range_image = decode_lidar_features(range_image)
        return range_image

      elems = [ri_indices, ri_ranges, num_points]
      if point_features is not None:
        elems.append(point_features)
      range_images = tf.map_fn(
          fn, elems=elems, dtype=points_vehicle_frame_dtype, back_prop=False)

      return range_images, ri_indices, ri_ranges