# -*- coding: utf-8 -*-
"""3.extract_points_cloud_through_mask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wl8vS4amzx12kSsdo737U30-Vq4NAQ-K
"""

!rm -rf waymo-od > /dev/null
!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od
!cd waymo-od && git branch -a
!cd waymo-od && git checkout remotes/origin/master
!pip3 install --upgrade pip

!pip3 install waymo-open-dataset-tf-2-11-0==1.6.1

import os
import tensorflow.compat.v1 as tf
import math
import numpy as np
import itertools
import matplotlib.pyplot as plt
import pickle
tf.enable_eager_execution()

from waymo_open_dataset.utils import range_image_utils
from waymo_open_dataset.utils import transform_utils
from waymo_open_dataset.utils import  frame_utils
from waymo_open_dataset import dataset_pb2 as open_dataset

from google.colab import drive

drive.mount('/content/gdrive')
FILENAME = '/content/gdrive/My Drive/ColabNotebooks/tfrecord/individual_files_training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord'
dataset = tf.data.TFRecordDataset(FILENAME)
# 从文件路径中提取文件名
file_name = os.path.basename(FILENAME)
# 创建一个以文件名命名的文件夹
folder_path = os.path.join('/content/gdrive/My Drive/ColabNotebooks/extracted_points', file_name.split('.')[0])
os.makedirs(folder_path, exist_ok=True)

import os
import tensorflow as tf
import pickle

frame_count = 1
mask_folder_path = "/content/gdrive/My Drive/ColabNotebooks/output_seg/"

for data in dataset:
    frame = open_dataset.Frame()
    frame.ParseFromString(bytearray(data.numpy()))
    (range_images, camera_projections, seg_labels, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)
    (point,cp_point) = frame_utils.convert_range_image_to_point_cloud(frame,range_images,camera_projections,range_image_top_pose)#获取激光点云
    points, cp_points = frame_utils.convert_range_image_to_point_cloud(frame, range_images, camera_projections, range_image_top_pose, keep_polar_features=True)
    points_all = np.concatenate(points, axis=0)
    found_file = False  # 设置一个标志位，表示是否找到了文件

    for filename in os.listdir(mask_folder_path):
        if filename.startswith(f"test_1_image_{frame_count}_"):
            image_path = os.path.join(mask_folder_path, filename)
            image = tf.io.read_file(image_path)

            # 解码图像文件
            image = tf.io.decode_png(image, channels=1)
            points2, cp_points, points_NLZ, points_intensity, points_elongation = convert_range_image_to_point_cloud_2(image, frame, range_images, camera_projections, range_image_top_pose,ri_index=0)
            points_all2 = np.concatenate(cp_points, axis=0)
            points_all2 = np.array(points_all2)
            print(points_all2)
            file_path = os.path.join(mask_folder_path, f"points_{frame_count}.pkl")
            with open(file_path, 'wb') as file:
                pickle.dump(points_all2, file)
            print(f"数据{frame_count}成功保存到 {file_path}")
            found_file = True
            break  # 找到一个匹配的文件后立即退出循环

    frame_count += 1  # 递增frame_count


    if not found_file:
        # 如果没有找到文件，则执行额外的操作
        points_bb = []
        # 遍历所有点，检查是否在任何边界框内
        for point in points_all:
            for laser_labels in frame.laser_labels:
                if (point[3] >= laser_labels.box.center_x - 0.5 * laser_labels.box.length and
                    point[3] <= laser_labels.box.center_x + 0.5 * laser_labels.box.length and
                    point[4] >= laser_labels.box.center_y - 0.5 * laser_labels.box.width and
                    point[4] <= laser_labels.box.center_y + 0.5 * laser_labels.box.width and
                    point[5] >= laser_labels.box.center_z - 0.5 * laser_labels.box.height and
                    point[5] <= laser_labels.box.center_z + 0.5 * laser_labels.box.height):
                    points_bb.append(point)

        points_bb = np.array(points_bb)
        file_path = os.path.join(folder_path, f"points_{frame_count}.pkl")
        with open(file_path, 'wb') as file:
            pickle.dump(points_bb, file)
        print(f"*******原始数据{frame_count}成功保存到 {file_path}")

def convert_range_image_to_point_cloud_2(image,frame, range_images, camera_projections, range_image_top_pose, ri_index=0):
    """
    Modified from the codes of Waymo Open Dataset.
    Convert range images to point cloud.
    Args:
        frame: open dataset frame
        range_images: A dict of {laser_name, [range_image_first_return, range_image_second_return]}.
        camera_projections: A dict of {laser_name,
            [camera_projection_from_first_return, camera_projection_from_second_return]}.
        range_image_top_pose: range image pixel pose for top lidar.
        ri_index: 0 for the first return, 1 for the second return.

    Returns:
        points: {[N, 3]} list of 3d lidar points of length 5 (number of lidars).
        cp_points: {[N, 6]} list of camera projections of length 5 (number of lidars).
    """
    calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)
    points = []
    cp_points = []
    points_NLZ = []
    points_intensity = []
    points_elongation = []

    frame_pose = tf.convert_to_tensor(np.reshape(np.array(frame.pose.transform), [4, 4]))
    # [H, W, 6]
    range_image_top_pose_tensor = tf.reshape(
        tf.convert_to_tensor(range_image_top_pose.data), range_image_top_pose.shape.dims
    )
    # [H, W, 3, 3]
    range_image_top_pose_tensor_rotation = transform_utils.get_rotation_matrix(
        range_image_top_pose_tensor[..., 0], range_image_top_pose_tensor[..., 1],
        range_image_top_pose_tensor[..., 2])
    range_image_top_pose_tensor_translation = range_image_top_pose_tensor[..., 3:]
    range_image_top_pose_tensor = transform_utils.get_transform(
        range_image_top_pose_tensor_rotation,
        range_image_top_pose_tensor_translation)

    # mask1 = tf.not_equal(image, 0)
    # mask_broadcasted1 = tf.tile(mask1, [1, 1, 4])  # 扩展到与 range_image_top_pose_tensor 相同的形状
    # range_image_top_pose_tensor = tf.where(mask_broadcasted1, tf.zeros_like(range_image_top_pose_tensor), range_image_top_pose_tensor)

    for c in calibrations:
      if c.name == open_dataset.LaserName.TOP:
        points_single, cp_points_single, points_NLZ_single, points_intensity_single, points_elongation_single \
            = [], [], [], [], []
        #for cur_ri_index in ri_index:
        range_image = range_images[c.name][ri_index]
        if len(c.beam_inclinations) == 0:  # pylint: disable=g-explicit-length-test
                beam_inclinations = range_image_utils.compute_inclination(
                    tf.constant([c.beam_inclination_min, c.beam_inclination_max]),
                    height=range_image.shape.dims[0])
        else:
                beam_inclinations = tf.constant(c.beam_inclinations)

        beam_inclinations = tf.reverse(beam_inclinations, axis=[-1])
        extrinsic = np.reshape(np.array(c.extrinsic.transform), [4, 4])

        range_image_tensor = tf.reshape(
                tf.convert_to_tensor(range_image.data), range_image.shape.dims)

        # lidar_image_mask = tf.cast(tf.greater_equal(range_image_tensor, 0), dtype=tf.bool)
        # range_image_tensor = tf.where(lidar_image_mask, range_image_tensor, tf.constant(255, dtype=tf.float32))
        #print(range_image_tensor)
        print('*****')
        mask = tf.not_equal(image, 0)

# 将 mask 扩展成与 range_image 相同的形状
        mask_broadcasted = tf.broadcast_to(mask, range_image_tensor.shape)

# 使用 mask 进行替换操作
        range_image_tensor = tf.where(mask_broadcasted, tf.zeros_like(range_image_tensor), range_image_tensor)
        #print(range_image_tensor)


        pixel_pose_local = None
        frame_pose_local = None
        if c.name == open_dataset.LaserName.TOP:
                pixel_pose_local = range_image_top_pose_tensor
                pixel_pose_local = tf.expand_dims(pixel_pose_local, axis=0)
                frame_pose_local = tf.expand_dims(frame_pose, axis=0)
        range_image_mask = range_image_tensor[..., 0] > 0
        range_image_NLZ = range_image_tensor[..., 3]
        range_image_intensity = range_image_tensor[..., 1]
        range_image_elongation = range_image_tensor[..., 2]
        range_image_cartesian = range_image_utils.extract_point_cloud_from_range_image(
                tf.expand_dims(range_image_tensor[..., 0], axis=0),
                tf.expand_dims(extrinsic, axis=0),
                tf.expand_dims(tf.convert_to_tensor(beam_inclinations), axis=0),
                pixel_pose=pixel_pose_local,
                frame_pose=frame_pose_local)
        #print(range_image_cartesian)
        range_image_cartesian = tf.squeeze(range_image_cartesian, axis=0)
        points_tensor = tf.gather_nd(range_image_cartesian,
                                         tf.where(range_image_mask))
        points_NLZ_tensor = tf.gather_nd(range_image_NLZ, tf.compat.v1.where(range_image_mask))
        points_intensity_tensor = tf.gather_nd(range_image_intensity, tf.compat.v1.where(range_image_mask))
        points_elongation_tensor = tf.gather_nd(range_image_elongation, tf.compat.v1.where(range_image_mask))
        cp = camera_projections[c.name][0]
        cp_tensor = tf.reshape(tf.convert_to_tensor(cp.data), cp.shape.dims)
        cp_points_tensor = tf.gather_nd(cp_tensor, tf.where(range_image_mask))

        points_single.append(points_tensor.numpy())
        cp_points_single.append(cp_points_tensor.numpy())
        points_NLZ_single.append(points_NLZ_tensor.numpy())
        points_intensity_single.append(points_intensity_tensor.numpy())
        points_elongation_single.append(points_elongation_tensor.numpy())

        points.append(np.concatenate(points_single, axis=0))
        cp_points.append(np.concatenate(cp_points_single, axis=0))
        points_NLZ.append(np.concatenate(points_NLZ_single, axis=0))
        points_intensity.append(np.concatenate(points_intensity_single, axis=0))
        points_elongation.append(np.concatenate(points_elongation_single, axis=0))


    return points, cp_points, points_NLZ, points_intensity, points_elongation